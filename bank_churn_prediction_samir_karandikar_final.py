# -*- coding: utf-8 -*-
"""Bank Churn Prediction-Samir Karandikar Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1M_14b8hXlWryvUQLb5gUTNz37kdWw-Xc

# **Bank Churn Prediction**
  Samir Karandikar
  
Project Description - Bank Churn Prediction

Objective:
Given a Bank customer, build a neural network-based classifier that can determine whether they will leave or not in the next 6 months.
Context: 
Businesses like banks that provide service have to worry about the problem of 'Churn' i.e. customers leaving and joining another service provider. It is important to understand which aspects of the service influence a customer's decision in this regard. Management can concentrate efforts on the improvement of service, keeping in mind these priorities.
"""

import tensorflow as tf
print(tf.__version__)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
import warnings
warnings.filterwarnings('ignore')
import pandas as pd
import numpy as np

from google.colab import drive
drive.mount('/content/drive')

"""## **1. Read the dataset**

Dataset is read as pandas dataframe df. 
Please see the explanation of each data variable below:
> 
*	RowNumber: Row number.
*	CustomerId: Unique identification key for different customers.
*	Surname: Surname of the customer
*	Credit Score: Credit score is a measure of an individual's ability to pay back the borrowed amount. It is the numerical representation of their creditworthiness. A credit score is a 3-digit number that falls in the range of 300-900, 900 being the highest.
*	Geography: The country to which the customer belongs.
*	Gender: The gender of the customer.
*	Age: Age of the customer.
*	Tenure: The period of time a customer has been associated with the bank.
*	Balance: The account balance (the amount of money deposited in the bank account) of the customer.
*	NumOfProducts: How many accounts, bank account affiliated products the person has.
*	HasCrCard: Does the customer have a credit card through the bank?
*	IsActiveMember: Subjective, but for the concept
*	EstimatedSalary: Estimated salary of the customer.
*	Exited: Did they leave the bank after all?




"""

# reading the CSV file into pandas dataframe
df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/bank.csv')  

pd.isnull(df).count()

df.dtypes

"""### **2. Drop the columns which are unique for all users like IDs (5 points)**"""

df  = df.drop(['RowNumber','CustomerId','Surname'], axis=1)

df.describe().T

"""## **3.Perform bivariate analysis and give your insights from the same (5 points)**"""

import seaborn as sns

sns.pairplot(data=df, hue = 'Exited')

df['Geography'].value_counts()

df['Gender'].value_counts()

for i in ['Geography', 'Gender' ]:
    plt.figure(figsize = (10,10))
    sns.countplot(df[i],hue='Exited', data=df)
    plt.xticks(rotation=90)
    plt.show()

"""## **Insights from Bivariate Analysis**
* SNS pairplot of the data using ‘Exited’ (y-variable) as hue is shown above. 
* Higher Number of Products ( 3 and 4) appears to have a high correlation with customers who are exiting. 
* Median age of the customers exiting appears to be higher than the median age of all customers.
* Lower credit score (<400) customers appear to be more like to exit than customers who have more than 400 credit score. 
* There appear to be two peaks for balance histogram and the exiting customers appear to be evenly distributed across the balance ranges. 
* Customers who have credit cards appear to have more likelihood of exiting. 
* There does not seem to be a correlation between category variables Gender and Geography and exited customers


"""

# Convert Geography as category variable to numeric values of 1, 2, & 3
df['Geography'] = df['Geography'].map({'France':1,'Spain':2, 'Germany':3})
df['Gender'] = df['Gender'].map({'Female':1,'Male':2})

#Convert the numeric values to one hot code to remove the order
df = pd.get_dummies(df, columns=['Geography', 'Gender'])

df.head()

"""##  **4. Distinguish the feature and target set and divide the data set into training and test sets (5 points)**"""

# Import `train_test_split` from `sklearn.model_selection`
from sklearn.model_selection import train_test_split

# Specify the data 
df1 = df.drop('Exited', axis = 1)
X=df1.iloc[:,0:13]

# Specify the target labels and flatten array
y= df.Exited


# Split the data up in train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

y_train =  np.array(y_train)
y_test =  np.array(y_test)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

"""## **5. Normalize the train and test data (10points)**"""

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()

X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

"""## **DEEP NEURAL NETWORK**
## **6. Initialize & build the model. Identify the points of improvement and implement the same. (20)**
"""

# Using Tensorflow Keras instead of the original Keras

from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
import tensorflow as tf
import tensorflow 

from tensorflow import keras
from keras.layers import Dense

ncols = X_train.shape[0]

class MySequential(keras.models.Sequential):
  def __init__(self, **kwargs):
    super(MySequential, self).__init__(**kwargs)

  def predict_classes(self, x, batch_size=32, verbose=0):
    proba = self.predict(x, batch_size=batch_size, verbose=verbose)
    return (proba > 0.5).astype('int32')

def define_model():
    model = MySequential()
    model.add(keras.layers.Dense(256, activation = 'relu', input_shape=(13,)))

    opt = keras.optimizers.Adam(learning_rate = 0.00005)
    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy', 'mae', 'mse'])
    
    return model

# Test

model = define_model()


# second hidden layer
model.add(Dense(64, activation='relu'))
# third hidden layer
model.add(Dense(20, activation='relu'))

# Add an output layer with one neuron and no activation specified
model.add(Dense(1, activation = 'relu'))

epochs = 50

model.summary()

history = model.fit(X_train, y_train, epochs=epochs, validation_split = 0.2, verbose = False)

hist  = pd.DataFrame(history.history)
hist['epoch'] = history.epoch
print(hist)

import matplotlib.pyplot as plt

plt.plot(hist['accuracy'])
plt.plot(hist['val_accuracy'])
plt.legend(("train" , "valid") , loc =0)

# Plot of Mean Square Error

plt.plot(hist['mse'])
plt.plot(hist['val_mse'])
plt.legend(("train" , "valid") , loc =0)

plt.plot(hist['mae'])
plt.plot(hist['val_mae'])
plt.legend(("train" , "valid") , loc =0)

results = model.evaluate(X_test, y_test)

print(model.metrics_names)
print(results)

"""## **Points of Improvement**

The accuracy of the test data is 0.858 which provides the best results so far.  Various runs were made of the deep neural networks model with different values of hyperparameters, starting with different number of hidden layers and the number of neurons in each layer were varied. Removing the second and third hidden layer completely and trying different number of neurons as well as changing the number of epochs. In general the best results were observed with the currently set hyperparameters. The validation data vs. the training data values were observed. When the learning rate was higher the model was unstable and the validation scores varied up and down. 

A step improvement in the model performance is observed when imbalance in the data set is removed. The accuracy reduces but there is significant improvement in the Recall score.

## **7. Predict the results using 0.5 as a threshold (10points)**
Keras implements predict_classes function with threshold value of 0.5 as follows:

    def predict_classes(self, x, batch_size=32, verbose=0):

    proba = self.predict(x, batch_size=batch_size, verbose=verbose)

    if proba.shape[-1] > 1:

      return proba.argmax(axis=-1)

    else:

      return (proba > 0.5).astype('int32')

### In the definition of MySelection the threshold has been entered as > 0.5

This was done to demonstrate that it was possible to set a customized threshold
"""

from sklearn.metrics import accuracy_score, confusion_matrix, precision_score
from sklearn.metrics import recall_score, f1_score, precision_recall_curve, auc

Y_pred_cls = model.predict_classes(X_test, batch_size=100, verbose=0)

"""## **8. Print the Accuracy score and confusion matrix (5 points)**"""

print('Recall_score: ' + str(recall_score(y_test, Y_pred_cls)))
print('Precision_score: ' + str(precision_score(y_test, Y_pred_cls)))
print('F-score: ' + str(f1_score(y_test, Y_pred_cls)))
print()
confusion_matrix(y_test, Y_pred_cls)

"""## **Observations**

In building the Deep Neural Network model, all the required steps were followed. Several combinations of hyper parameters were tried to improve the
 performance of the model using "accuracy" as the criteria. **The highest accuracy of 0.858** for the test data was obtained in this run. Confusion Matrix shows:
 TP = 180 ; 
 TN = 1536 ; 
 FN = 213 ; and 
 FP = 71

The **precision score of 0.717 is quite good** because the FP are comparatively fewer. Model falsely predicts fewer customers who are likely to exit than the ones who actually exit. 

It should be recognized that the **"Recall" score of 0.458** is not very good for the model and it may be because per the data set about 20% of customers have exited. Poor Recall score is because of the imbalance in the data set. 

The **imbalance** in the data set could be corrected by upsampling the Exited customer data. I have implemented this solution in steps below called R5. You will see that using oversampling method to boost the imbalanced class has improved to Recall score and maintained the Precision score.

# **In the following steps, called R5 the model is re-constructed after implementing oversampling to remove the imbalance. **

##  **4 (R5). Distinguish the feature and target set and divide the data set into training and test sets (5 points)**

## In revision R4, of the project it was observed that due to the imbalance in the data, the neural network provides low Recall score. In the major change implemented here, **oversampling technique** is used to boost the minority class which is the Exited customers.
"""

# import required modules 
from sklearn.datasets import make_classification 
from imblearn.over_sampling import RandomOverSampler 
  
# define dataset 
  
oversample = RandomOverSampler(sampling_strategy='minority') 
x_over, y_over = oversample.fit_resample(X, y)

# Split the data up in train and test sets
X_train, X_test, y_train, y_test = train_test_split(x_over, y_over, test_size=0.20, random_state=42)

y_train =  np.array(y_train)
y_test =  np.array(y_test)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

"""## **5 (R5). Normalize the train and test data (10points)**"""

from sklearn.preprocessing import StandardScaler

# Define the scaler 
scaler = StandardScaler().fit(X_train)

# Scale the train set
X_train = scaler.transform(X_train)

# Scale the test set
X_test = scaler.transform(X_test)

"""## **DEEP NEURAL NETWORK**
## **6 (R5). Initialize & build the model. Identify the points of improvement and implement the same. (20)**
"""

# Using Tensorflow Keras instead of the original Keras

from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
import tensorflow as tf
import tensorflow 

from tensorflow import keras
from keras.layers import Dense

ncols = X_train.shape[0]

class MySequential(keras.models.Sequential):
  def __init__(self, **kwargs):
    super(MySequential, self).__init__(**kwargs)

  def predict_classes(self, x, batch_size=32, verbose=0):
    proba = self.predict(x, batch_size=batch_size, verbose=verbose)
    return (proba > 0.5).astype('int32')

def define_model():
    model = MySequential()
    model.add(keras.layers.Dense(256, activation = 'relu', input_shape=(13,)))

    opt = keras.optimizers.Adam(learning_rate = 0.00005)
    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy', 'mae', 'mse'])
    
    return model

# Test

model = define_model()


# second hidden layer
model.add(Dense(64, activation='relu'))
# third hidden layer
model.add(Dense(20, activation='relu'))

# Add an output layer with one neuron and no activation specified
model.add(Dense(1, activation = 'relu'))

epochs = 60

model.summary()

history = model.fit(X_train, y_train, epochs=epochs, validation_split = 0.2, verbose = False)

hist  = pd.DataFrame(history.history)
hist['epoch'] = history.epoch
print(hist)

import matplotlib.pyplot as plt

plt.plot(hist['accuracy'])
plt.plot(hist['val_accuracy'])
plt.legend(("train" , "valid") , loc =0)

# Plot of Mean Square Error

plt.plot(hist['mse'])
plt.plot(hist['val_mse'])
plt.legend(("train" , "valid") , loc =0)

plt.plot(hist['mae'])
plt.plot(hist['val_mae'])
plt.legend(("train" , "valid") , loc =0)

results = model.evaluate(X_test, y_test)

print(model.metrics_names)
print(results)

"""## **Points of Improvement**

In R5 of the solution implemented, the accuracy of the test data is 0.804 which is less than the result without upsampling.  Various runs were made of the deep neural networks model with different values of hyperparameters, starting with different number of hidden layers and the number of neurons in each layer were varied. Removing the second and third hidden layer completely and trying different number of neurons as well as changing the number of epochs. In general the best results were observed with the currently set hyperparameters. The validation data vs. the training data values were observed. When the learning rate was higher the model was unstable and the validation scores varied up and down. 

Validation data tracks close to training data as the number of epochs are 60. There is slight overfitting observed but without loss of accuracy in the testing data. 

When the imbalance in the data was removed by the use of oversampling technique in step 4, there was significant improvement in the model performance in terms of Recall score.

A step improvement in the model performance is observed when imbalance in the data set is removed. The accuracy reduced from 85.8% to 80.4% but the Recall score improved significantly.

## **7. Predict the results using 0.5 as a threshold (10points)**
Keras implements predict_classes function with threshold value of 0.5 as follows:

    def predict_classes(self, x, batch_size=32, verbose=0):

    proba = self.predict(x, batch_size=batch_size, verbose=verbose)

    if proba.shape[-1] > 1:

      return proba.argmax(axis=-1)

    else:

      return (proba > 0.5).astype('int32')

### In the definition of MySelection the threshold has been entered as > 0.5

This was done to demonstrate that it was possible to set a customized threshold
"""

from sklearn.metrics import accuracy_score, confusion_matrix, precision_score
from sklearn.metrics import recall_score, f1_score, precision_recall_curve, auc

Y_pred_cls = model.predict_classes(X_test, batch_size=100, verbose=0)

"""## **8. Print the Accuracy score and confusion matrix (5 points)**"""

print('Recall_score: ' + str(recall_score(y_test, Y_pred_cls)))
print('Precision_score: ' + str(precision_score(y_test, Y_pred_cls)))
print('F-score: ' + str(f1_score(y_test, Y_pred_cls)))
print()
confusion_matrix(y_test, Y_pred_cls)

"""## **Observations**
In Revision 4 of the solution file, the imbalance correction step was not implemented. As a result the following results were observed:
* In building the Deep Neural Network model, all the required steps were followed. Several combinations of hyper parameters were tried to improve the
 performance of the model using "accuracy" as the criteria. **The highest accuracy of 0.858** for the test data was obtained in this run. Confusion Matrix shows:
 TP = 180 ; 
 TN = 1536 ; 
 FN = 213 ; and 
 FP = 71

* The **precision score of 0.717 is quite good** because the FP are quite few. Model falsely predicts fewer customers who are likely to exit than the ones who actually exit. 

* It should be recognized that the **"Recall" score of 0.458** is not very good for the model and it may be because only 0% of customers have exited. *

## There was **imbalance** in the data set and it was improved by upsampling the Exited customer data. I have implemented this solution in this (R5) file. 
* As a result **Recall score increased from 0.458 to 0.812.**
* At the same time, **Precision Score increased from 0.717 to 0.7915.** 
* Most importantly, **F-score for the model increased from 0.559 to 0.801**

# Considering the business objectives of the bank it would help to have a model that more accurately predicts who is likely to exit the bank which is the Recall score. 
"""